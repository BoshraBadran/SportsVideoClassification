{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Videos from Youtube \n",
    "\n",
    "Construct a folder named Dataset in your working directory to store the whole dataset. Construct a new folder named Videos inside it where you can download the videos.\n",
    "You need to install few dependencies like youtube-dl and ffmpeg.\n",
    "\n",
    "\n",
    "`sudo apt-get install ffmpeg\n",
    " sudo pip install youtube-dl\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import csv \n",
    "import sys\n",
    "import subprocess as sp\n",
    "import youtube_dl\n",
    "import platform\n",
    "import os\n",
    "\n",
    "\n",
    "if platform.system() == 'Linux':\n",
    "    FFMPEG_BIN = \"ffmpeg\" # on Linux \n",
    "\n",
    "if platform.system() == 'Windows':\n",
    "    FFMPEG_BIN = \"ffmpeg.exe\" # on windows\n",
    "\n",
    "\n",
    "ydl = youtube_dl.YoutubeDL({'outtmpl': '%(id)s%(ext)s'})\n",
    " \n",
    "\n",
    "# Change this to the where you placed the video dataset file    \n",
    "CSV_FILE = \"./Video-Dataset.csv\"\n",
    "    \n",
    "f = open(CSV_FILE, 'r')\n",
    "dataset_folder = \"Dataset\" + \"/\" + \"Videos\"\n",
    "\n",
    "reader = csv.reader(f)\n",
    "\n",
    "for row in reader:\n",
    "    category = str(row[0]).rstrip()\n",
    "    link = str(row[1]).rstrip()\n",
    "    time = str(row[2]).rstrip()\n",
    "    dur = str(row[3]).rstrip()\n",
    "    \n",
    "    vid_name = link.split('=')[1].replace('-','_') + \".mp4\"\n",
    "    \n",
    "    directory = dataset_folder + \"/\" + category \n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory) \n",
    "       \n",
    "    with ydl:\n",
    "        result = ydl.extract_info(link,download=False)\n",
    "        \n",
    "    if 'entries' in result:\n",
    "       # Can be a playlist or a list of videos\n",
    "        video = result['entries'][0]\n",
    "    else:\n",
    "    # Just a video\n",
    "        video = result\n",
    "  \n",
    "    \n",
    "    if os.path.exists(directory + \"/\" + vid_name) == False:\n",
    "        \n",
    "        formats = video['formats']\n",
    "        formats = [x for x in formats if x['vcodec'] != 'none']\n",
    "        formats = sorted(formats, key=lambda k: k['width'], reverse=True)\n",
    "        \n",
    "        for _format in formats:\n",
    "            if _format['vcodec'] != 'none':\n",
    "                url = _format['url']\n",
    "                command = [ FFMPEG_BIN,\n",
    "                            '-ss',time,\n",
    "                            '-t',dur,\n",
    "                            '-i', url, \n",
    "                             directory + \"/\" + vid_name ]\n",
    "                ffmpeg = sp.Popen(command, stderr=sp.STDOUT,stdout = sp.PIPE)\n",
    "                out, err = ffmpeg.communicate()\n",
    "                if os.path.exists(directory + \"/\" + vid_name):\n",
    "                    break;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Keyframes from Videos\n",
    "In this step, we extract keyframes from each video using the technique of sum of absolute differences.For this you need to install opencv. One easy way to install opencv is using pip as :\n",
    "\n",
    "`sudo pip install opencv-python\n",
    "`\n",
    "Construct a new directory inside Dataset called Keyframes to store the key frames for each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import operator\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') # Must be before importing matplotlib.pyplot or pylab!\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "\n",
    "#Setting fixed threshold criteria\n",
    "USE_THRESH = False\n",
    "#fixed threshold value\n",
    "THRESH = 0.6\n",
    "#Setting fixed threshold criteria\n",
    "USE_TOP_ORDER = True\n",
    "#Setting local maxima criteria\n",
    "USE_LOCAL_MAXIMA = False\n",
    "#Number of top sorted frames\n",
    "NUM_TOP_FRAMES = 7\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def smooth(x, window_len=13, window='hanning'):\n",
    "    \"\"\"smooth the data using a window with requested size.\n",
    "    \n",
    "    This method is based on the convolution of a scaled window with the signal.\n",
    "    The signal is prepared by introducing reflected copies of the signal \n",
    "    (with the window size) in both ends so that transient parts are minimized\n",
    "    in the begining and end part of the output signal.\n",
    "    \n",
    "    input:\n",
    "        x: the input signal \n",
    "        window_len: the dimension of the smoothing window\n",
    "        window: the type of window from 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\n",
    "            flat window will produce a moving average smoothing.\n",
    "    output:\n",
    "        the smoothed signal\n",
    "        \n",
    "    example:\n",
    "    import numpy as np    \n",
    "    t = np.linspace(-2,2,0.1)\n",
    "    x = np.sin(t)+np.random.randn(len(t))*0.1\n",
    "    y = smooth(x)\n",
    "    \n",
    "    see also: \n",
    "    \n",
    "    numpy.hanning, numpy.hamming, numpy.bartlett, numpy.blackman, numpy.convolve\n",
    "    scipy.signal.lfilter \n",
    "    \"\"\"\n",
    "    print(len(x), window_len)\n",
    "    if x.ndim != 1:\n",
    "        raise ValueError, \"smooth only accepts 1 dimension arrays.\"\n",
    "\n",
    "    if x.size < window_len:\n",
    "        raise ValueError, \"Input vector needs to be bigger than window size.\"\n",
    "\n",
    "    if window_len < 3:\n",
    "        return x\n",
    "\n",
    "    if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n",
    "        raise ValueError, \"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\"\n",
    "\n",
    "    s = np.r_[2 * x[0] - x[window_len:1:-1],\n",
    "              x, 2 * x[-1] - x[-1:-window_len:-1]]\n",
    "    #print(len(s))\n",
    "\n",
    "    if window == 'flat':  # moving average\n",
    "        w = np.ones(window_len, 'd')\n",
    "    else:\n",
    "        w = getattr(np, window)(window_len)\n",
    "    y = np.convolve(w / w.sum(), s, mode='same')\n",
    "    return y[window_len - 1:-window_len + 1]\n",
    "\n",
    "#Class to hold information about each frame\n",
    "\n",
    "\n",
    "class Frame:\n",
    "    def __init__(self, id, frame, value):\n",
    "        self.id = id\n",
    "        self.frame = frame\n",
    "        self.value = value\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        if self.id == other.id:\n",
    "            return self.id < other.id\n",
    "        return self.id < other.id\n",
    "\n",
    "    def __gt__(self, other):\n",
    "        return other.__lt__(self)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.id == other.id and self.id == other.id\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        return not self.__eq__(other)\n",
    "\n",
    "\n",
    "def rel_change(a, b):\n",
    "   x = (b - a) / max(a, b)\n",
    "   print(x)\n",
    "   return x\n",
    "\n",
    "\n",
    "#print(\"Video :\" + videopath)\n",
    "#print(\"Frame Directory: \" + dir)\n",
    "\n",
    "def divideFrames(videopath,kf_dir,len_window):\n",
    "    cap = cv2.VideoCapture(str(videopath))\n",
    "    \n",
    "    \n",
    "    curr_frame = None\n",
    "    prev_frame = None\n",
    "    \n",
    "    frame_diffs = []\n",
    "    frames = []\n",
    "    ret, frame = cap.read()\n",
    "    i = 1\n",
    "    \n",
    "    while(ret):\n",
    "        luv = cv2.cvtColor(frame, cv2.COLOR_BGR2LUV)\n",
    "        curr_frame = luv\n",
    "        if curr_frame is not None and prev_frame is not None:\n",
    "            #logic here\n",
    "            diff = cv2.absdiff(curr_frame, prev_frame)\n",
    "            count = np.sum(diff)\n",
    "            frame_diffs.append(count)\n",
    "            frame = Frame(i, frame, count)\n",
    "            frames.append(frame)\n",
    "        prev_frame = curr_frame\n",
    "        i = i + 1\n",
    "        ret, frame = cap.read()\n",
    "    \"\"\"\n",
    "        cv2.imshow('frame',luv)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \"\"\"\n",
    "    cap.release()\n",
    "    #cv2.destroyAllWindows()\n",
    "    \n",
    "    if USE_TOP_ORDER:\n",
    "        # sort the list in descending order\n",
    "        diff_array = np.array(frame_diffs)\n",
    "        sm_diff_array = smooth(diff_array, len_window)\n",
    "        frames.sort(key=operator.attrgetter(\"value\"), reverse=True)\n",
    "        for keyframe in frames[:NUM_TOP_FRAMES]:\n",
    "            name = \"frame_\" + str(keyframe.id) + \".jpg\"\n",
    "            cv2.imwrite(kf_dir + \"/\" + name, keyframe.frame)\n",
    "    \n",
    "    if USE_THRESH:\n",
    "        print(\"Using Threshold\")\n",
    "        for i in range(1, len(frames)):\n",
    "            if (rel_change(np.float(frames[i - 1].value), np.float(frames[i].value)) >= THRESH):\n",
    "                #print(\"prev_frame:\"+str(frames[i-1].value)+\"  curr_frame:\"+str(frames[i].value))\n",
    "                name = \"frame_\" + str(frames[i].id) + \".jpg\"\n",
    "                cv2.imwrite(kf_dir + \"/\" + name, frames[i].frame)\n",
    "    \n",
    "    \n",
    "    if USE_LOCAL_MAXIMA:\n",
    "        print(\"Using Local Maxima\")\n",
    "        diff_array = np.array(frame_diffs)\n",
    "        sm_diff_array = smooth(diff_array, len_window)\n",
    "        frame_indexes = np.asarray(argrelextrema(sm_diff_array, np.greater))[0]\n",
    "        for i in frame_indexes:\n",
    "            name = \"frame_\" + str(frames[i - 1].id) + \".jpg\"\n",
    "            #print(dir+name)\n",
    "            cv2.imwrite(kf_dir +\"/\" + name, frames[i - 1].frame)\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(40, 20))\n",
    "    plt.locator_params(numticks=100)\n",
    "    plt.stem(sm_diff_array)\n",
    "    plt.savefig(kf_dir +\"/\" + \"/\"+ 'plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Directory where Videos are located\n",
    "vidpath = \"./Dataset/Videos\"\n",
    "\n",
    "# Directory where Keyframes are going to be stored\n",
    "keypath = \"./Dataset/Keyframes\"\n",
    "\n",
    "# smoothing window threshold for moving camera\n",
    "CAM_MOV_THRESH = 18\n",
    "\n",
    "for root, dirs, files in os.walk(vidpath):\n",
    "    for cat in dirs:\n",
    "        \n",
    "        kdir =  keypath +\"/\" + cat\n",
    "        \n",
    "        if not os.path.exists(kdir):\n",
    "            os.makedirs(kdir)\n",
    "    \n",
    "        for root,dirs,vids in os.walk(vidpath+\"/\"+cat): \n",
    "            \n",
    "            for v in vids:\n",
    "            \n",
    "                vid_name = str(v).split(\".\")[0]\n",
    "                kf_dir = kdir + \"/\" + vid_name\n",
    "                \n",
    "                if not os.path.exists(kf_dir):\n",
    "                    os.makedirs(kf_dir)\n",
    "                \n",
    "                videopath = vidpath+\"/\"+cat+\"/\"+v\n",
    "                                \n",
    "                divideFrames(videopath,kf_dir,CAM_MOV_THRESH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Object bank representation for each extracted keyframe \n",
    "Construct a new directory inside Dataset folder called Objectbank to store the objectbank representation for each video key frame.To construct object bank for each frame, we used the code given on Project website:\n",
    "http://vision.stanford.edu/projects/objectbank/CPP_release.zip. \n",
    "\n",
    "Download and compile the C++ code to obtain executable `OBmain` which will be used in this python code.\n",
    "\n",
    "Create another directory named Objectbank inside Dataset folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Dataset/Keyframes/Badminton/_5QkmjT7v9k\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import subprocess as sp\n",
    "import sys\n",
    "\n",
    "# Directory where keyframes are located\n",
    "rootkeyframes = \"./Dataset/Keyframes/\"\n",
    "\n",
    "if not rootkeyframes.endswith('/'):\n",
    "    rootkeyframes = rootkeyframes + \"/\"   \n",
    "\n",
    "# Directory where object bank is created\n",
    "rootobjbank = \"./Dataset/Objectbank\"\n",
    "\n",
    "if not rootobjbank.endswith('/'):\n",
    "    rootobjbank = rootobjbank + \"/\"\n",
    "\n",
    "OB_BANK_GEN = \"./OBmain\"\n",
    "\n",
    "cat_dirs = os.walk(rootkeyframes).next()[1]\n",
    "\n",
    "for category in cat_dirs:\n",
    "    \n",
    "    #print(\"*****\"+category+\"****\")\n",
    "    \n",
    "    # Make category directory in object bank root folder\n",
    "    obj_cat_dir = rootobjbank + category\n",
    "    \n",
    "    if not os.path.exists(obj_cat_dir):\n",
    "            os.makedirs(obj_cat_dir)\n",
    "    \n",
    "    \n",
    "    kfdir_path = rootkeyframes + category\n",
    "    keyframe_dirs = os.walk(kfdir_path).next()[1]\n",
    "    \n",
    "    for kfdirs in keyframe_dirs:\n",
    "        \n",
    "        # Make directory for each video in each category\n",
    "        obj_kf_dir = obj_cat_dir + \"/\" + kfdirs\n",
    "        if not os.path.exists(obj_kf_dir):\n",
    "            os.makedirs(obj_kf_dir)\n",
    "        \n",
    "        \n",
    "        kf_path = kfdir_path + \"/\"+kfdirs\n",
    "        print(kf_path)\n",
    "        \n",
    "        if os.path.exists(kf_path+\"/plot.png\"):\n",
    "            os.remove(kf_path+\"/plot.png\")\n",
    "        \n",
    "        inputdirectory = os.path.abspath(kf_path) + \"/\"\n",
    "        outputdirectory = os.path.abspath(obj_kf_dir ) + \"/\"\n",
    "        \n",
    "        \n",
    "        sp.call([OB_BANK_GEN , inputdirectory , outputdirectory])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct VGG16 feature bank representation for each extracted keyframe \n",
    "Construct a new directory inside Dataset folder called VGGfeaturebank to store the feature representation for each video key frame.To construct feature bank for each frame, we used the pre-trained VGG16 network available in keras library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import backend \n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "# load the model\n",
    "model = VGG16()\n",
    "\n",
    "\n",
    "rootkeyframes = \"./Dataset/Keyframes/\"\n",
    "\n",
    "if not rootkeyframes.endswith('/'):\n",
    "    rootkeyframes = rootkeyframes + \"/\"   \n",
    "\n",
    "# Directory where vgg object bank is created\n",
    "rootvggobjbank = \"./Dataset/VGGbank\"\n",
    "\n",
    "if not rootvggobjbank.endswith('/'):\n",
    "    rootkeyframes = rootkeyframes + \"/\"\n",
    "\n",
    "\n",
    "cat_dirs = os.walk(rootkeyframes).next()[1]\n",
    "\n",
    "for category in cat_dirs:\n",
    "    \n",
    "    # Make category directory in object bank root folder\n",
    "    obj_cat_dir = rootvggobjbank + category\n",
    "    \n",
    "    if not os.path.exists(obj_cat_dir):\n",
    "            os.makedirs(obj_cat_dir)\n",
    "    \n",
    "    \n",
    "    kfdir_path = rootkeyframes + category\n",
    "    keyframe_dirs = os.walk(kfdir_path).next()[1]\n",
    "    \n",
    "    for kfdirs in keyframe_dirs:\n",
    "        \n",
    "        # Make directory for each video in each category\n",
    "        obj_kf_dir = obj_cat_dir + \"/\" + kfdirs\n",
    "        if not os.path.exists(obj_kf_dir):\n",
    "            os.makedirs(obj_kf_dir)\n",
    "        \n",
    "        \n",
    "        kf_path = kfdir_path + \"/\"+kfdirs\n",
    "        #print(kf_path)\n",
    "        \n",
    "        if os.path.exists(kf_path+\"/plot.png\"):\n",
    "            os.remove(kf_path+\"/plot.png\")\n",
    "        \n",
    "        inputdirectory = os.path.abspath(kf_path) + \"/\"\n",
    "        outputdirectory = os.path.abspath(obj_kf_dir ) + \"/\"\n",
    "        \n",
    "        \n",
    "        for fname in glob.glob(inputdirectory + \"/*.jpg\"):\n",
    "            \n",
    "            img_name = fname.split('.')[0].split('/')[-1] \n",
    "                       \n",
    "            # load an image from file\n",
    "            image = load_img(fname, target_size=(224, 224))\n",
    "            # convert the image pixels to a numpy array\n",
    "            image = img_to_array(image)\n",
    "            # reshape data for the model\n",
    "            image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "            # prepare the image for the VGG model\n",
    "            image = preprocess_input(image)\n",
    "            # predict the probability across all output classes\n",
    "            yhat = model.predict(image)\n",
    "            # convert the probabilities to class labels\n",
    "            label = decode_predictions(yhat)\n",
    "            # with a Sequential model\n",
    "            get_2ndlast_layer_output = backend.function([model.layers[0].input],\n",
    "                                  [model.layers[-2].output])\n",
    "            layer_output = get_2ndlast_layer_output([image])[0]\n",
    "            \n",
    "            out_file_name = outputdirectory + img_name + \"_vgg.feat\"\n",
    "            \n",
    "            np.savetxt(out_file_name, layer_output)\n",
    "            #print(\"Generated \"+ out_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
