{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category to label Correspondence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_names = { 0 : 'Badminton', \n",
    "              1 : 'Bocce',\n",
    "              2 : 'Croquet',\n",
    "              3 : 'Polo',\n",
    "              4 : 'RockClimbing',\n",
    "              5 : 'Rowing',\n",
    "              6 : 'Sailing',\n",
    "              7 : 'Snowboarding'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_vggobjbank = './Dataset/VGGbank/'\n",
    "\n",
    "cat_dirs = os.walk(root_vggobjbank).next()[1]\n",
    "\n",
    "count = 0;\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Reading the data\n",
    "\n",
    "for cat in cat_dirs:\n",
    "    \n",
    "    label = count\n",
    "    video_dirs_path = root_vggobjbank + \"/\" + cat\n",
    "    video_dirs =  os.walk(video_dirs_path).next()[1]\n",
    "    \n",
    "    for vid_dir in video_dirs:\n",
    "        vid_dir_path = video_dirs_path  + \"/\"+ vid_dir \n",
    "        \n",
    "        x_con = []\n",
    "        for fname in glob.glob(vid_dir_path + \"/*.feat\"):\n",
    "            x = np.loadtxt(fname)\n",
    "            #x = np.reshape(x,[-1,1])\n",
    "            x_con.append(x)\n",
    "        \n",
    "        X.append(np.asarray(x_con));\n",
    "        y.append(label)\n",
    "        \n",
    "            \n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing the data into test/train split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)\n",
    "y_train = np.reshape(y_train,[-1,1])\n",
    "y_test = np.reshape(y_test,[-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.squeeze(y_train)\n",
    "y_test = np.squeeze(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function append all the features for each frame together to generate feature vector for whole video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vidFeat(X):\n",
    "    [num_videos, num_frames,feat_length] = X.shape\n",
    "    X_v = []\n",
    "    for vid_num in xrange(0,num_videos):\n",
    "        x = np.reshape(X[vid_num],[-1,1])\n",
    "        X_v.append(x)\n",
    "    return  np.squeeze(np.asarray(X_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function normalize the input vector for each frame between [-1,1] and append all the features together\n",
    "to generate feature vector for whole video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_vidFeat(X):\n",
    "    [num_videos, num_frames,feat_length] = X.shape\n",
    "    X_sc = []\n",
    "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    for vid_num in xrange(0,num_videos):\n",
    "        scaler.fit(np.reshape(X[vid_num],[-1,1]))\n",
    "        x = scaler.transform(np.reshape(X[vid_num],[-1,1]))\n",
    "        X_sc.append(x)\n",
    "    return  np.squeeze(np.asarray(X_sc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Non Scaled video Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nsc = norm_vidFeat(X_train)\n",
    "X_test_nsc = norm_vidFeat(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.000000\n",
      "Test set score: 0.887500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(200,), max_iter=500, alpha=1e-4,\n",
    "                    solver='lbfgs', verbose=10, tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=.1,learning_rate='adaptive')\n",
    "\n",
    "mlp.fit(X_train_nsc, y_train)\n",
    "print(\"Training set score: %f\" % mlp.score(X_train_nsc, y_train))\n",
    "print(\"Test set score: %f\" % mlp.score(X_test_nsc, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Scaled video features  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sc = norm_vidFeat(X_train)\n",
    "X_test_sc = norm_vidFeat(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Multi Layer perceptron for classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.000000\n",
      "Test set score: 0.887500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(200,), max_iter=500, alpha=1e-4,\n",
    "                    solver='lbfgs', verbose=10, tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=.1,learning_rate='adaptive')\n",
    "\n",
    "mlp.fit(X_train_sc, y_train)\n",
    "print(\"Training set score: %f\" % mlp.score(X_train_sc, y_train))\n",
    "print(\"Test set score: %f\" % mlp.score(X_test_sc, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using Cross-Validated Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "LR_clf = LogisticRegressionCV(cv=5, random_state=0,multi_class='multinomial')\n",
    "LR_clf.fit(X_train_nsc, y_train)\n",
    "y_pred_LR = LR_clf.predict(X_test_nsc)\n",
    "\n",
    "Acc_LR = accuracy_score(y_test, y_pred_LR)\n",
    "print(Acc_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using Multiclass Linear SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "SVC_clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "SVC_clf.fit(X_train_nsc, y_train)\n",
    "y_pred_SVC=SVC_clf.predict(X_test_nsc)\n",
    "Acc_SVC = accuracy_score(y_test, y_pred_SVC)\n",
    "print(Acc_SVC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "498.883px",
    "left": "631.593px",
    "right": "20px",
    "top": "156.993px",
    "width": "798.173px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
